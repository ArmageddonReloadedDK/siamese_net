{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_utils import get_pairs,get_dataset_info,estimate_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imread\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Lambda\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape=(128,128,3)\n",
    "main_folder_name='dataset'\n",
    "max_positive_pairs_count=8000\n",
    "max_negative_pairs_count=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Dataset info\n",
      "\n",
      "image shape =  (128, 128, 3)\n",
      "image weight =  48.0  KiB\n",
      "number of classes =  3\n",
      "number of pictures =  132\n",
      "positive pairs count = 7482\n",
      "positive pairs images weight = 0.685  GiB\n",
      "negative pairs count = 9942\n",
      "negative pairs images weight = 0.91  GiB\n",
      "\n",
      "total memory size = 1.5950000000000002  GiB\n"
     ]
    }
   ],
   "source": [
    "get_dataset_info(main_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Estimated info\n",
      "\n",
      "desired positive pairs count = 8000\n",
      "positive pairs images weight = 0.732  GiB\n",
      "\n",
      "desired negative pairs count = 10000\n",
      "negative pairs images weight = 0.916  GiB\n",
      "\n",
      "total memory size = 1.6480000000000001  GiB\n"
     ]
    }
   ],
   "source": [
    "estimate_dataset(main_folder_name,\n",
    "                 max_positive_pairs_count,\n",
    "                 max_negative_pairs_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation began\n",
      "\n",
      "Calculation is done\n",
      "\n",
      "passed seconds:  9.806  seconds\n"
     ]
    }
   ],
   "source": [
    "pairs,labels=get_pairs(main_folder_name,\n",
    "                       max_positive_pairs_count,\n",
    "                       max_negative_pairs_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_base_network():\n",
    "    input = Input(shape=image_shape)\n",
    "    x = Flatten()(input)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.1,)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "\n",
    "    return Model(inputs=input, outputs=x)\n",
    "\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_VGG():\n",
    "    \n",
    "    #model_vgg = VGG16(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    model = Sequential(VGG16(weights='imagenet', include_top=False, input_shape=image_shape).layers)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_network = initialize_base_network()\n",
    "base_network = get_VGG()\n",
    "base_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_a = Input(shape=image_shape)\n",
    "vect_output_a = base_network(input_a)\n",
    "\n",
    "input_b = Input(shape=image_shape)\n",
    "vect_output_b = base_network(input_b)\n",
    "\n",
    "\n",
    "output = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([vect_output_a, vect_output_b])\n",
    "\n",
    "# specify the inputs and output of the model\n",
    "model = Model([input_a, input_b], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss_with_margin(margin):\n",
    "    def contrastive_loss(y_true, y_pred):\n",
    "        square_pred = K.square(y_pred)\n",
    "        margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "        return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "    return contrastive_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = RMSprop()\n",
    "model.compile(loss=contrastive_loss_with_margin(margin=1), optimizer=rms)\n",
    "history = model.fit([pairs[:,0],pairs[:,1]], \n",
    "                    labels, \n",
    "                    epochs=20, \n",
    "                    batch_size=16,\n",
    "                    validation_split=0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_neuro",
   "language": "python",
   "name": "env_neuro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
